{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1I1WvtKI1gErbnJLG2vqYHOfjB7i9KshR","timestamp":1732681840400},{"file_id":"1NvlQ_LlpEMiaIPwHVdqzLRkn7dPgF7mw","timestamp":1730938797200},{"file_id":"1OPukqZbKSTcEA8lVK0D1An0F-mTpL4gm","timestamp":1730407430126}],"toc_visible":true,"authorship_tag":"ABX9TyNvOGBND0rTjtaQyL0KhJKQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","# Copyright 2024 Forusone(shins777@gmail.com)\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"metadata":{"id":"4rr1pppYJpcq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AI Agent - Orchestration with LLM 2"],"metadata":{"id":"D9qIHOgSLuRy"}},{"cell_type":"markdown","source":["## Set configuration"],"metadata":{"id":"xPIk2CC5J5wc"}},{"cell_type":"code","source":["# @title Package install\n","%pip install --upgrade --quiet --user google-cloud-aiplatform"],"metadata":{"id":"51-wpUMCJ-n1","executionInfo":{"status":"ok","timestamp":1735320922544,"user_tz":-540,"elapsed":28597,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b3b681d-b64f-41e9-b1a8-664f4eca224e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/6.9 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/6.9 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/6.9 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m6.8/6.9 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# @title Authentication to access to GCP\n","\n","# To use markdown for output data from LLM\n","from IPython.display import display, Markdown\n","\n","# Use OAuth to access the GCP environment.\n","import sys\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1735320935470,"user_tz":-540,"elapsed":12923,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"id":"Z0hzaZv1LuRy"},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Lab Execution"],"metadata":{"id":"gCZP9ElhKXxG"}},{"cell_type":"code","source":["# @title Define constants\n","\n","PROJECT_ID = \"ai-hangsik\"  # @param {type:\"string\"}\n","LOCATION = \"us-central1\"  # @param {type:\"string\"}\n","MODEL_NAME = \"gemini-1.5-flash-002\" # @param {type:\"string\"}"],"metadata":{"cellView":"form","id":"ydJ5ZNXTKcjv","executionInfo":{"status":"ok","timestamp":1735320935567,"user_tz":-540,"elapsed":96,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# @title Import packages\n","\n","import vertexai\n","\n","from vertexai.generative_models import (\n","    GenerationConfig,\n","    GenerativeModel,\n","    HarmBlockThreshold,\n","    HarmCategory,\n","    GenerationResponse,\n","    Tool,\n","    Part,\n","    ChatSession\n",")\n","\n","from vertexai.preview.generative_models import grounding"],"metadata":{"executionInfo":{"status":"ok","timestamp":1735320955104,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"id":"ls6bnUx2LuRy"},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# @title Initialize Vertex AI\n","\n","# https://cloud.google.com/python/docs/reference/aiplatform/latest#initialization\n","vertexai.init(project=PROJECT_ID, location=LOCATION)\n","\n","# https://cloud.google.com/vertex-ai/generative-ai/docs/reference/python/latest/vertexai.generative_models.GenerativeModel\n","model = GenerativeModel(MODEL_NAME)"],"metadata":{"id":"9aqvBq1dKoXc","executionInfo":{"status":"ok","timestamp":1735320957703,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# @title Helper function\n","from vertexai.generative_models import ChatSession, GenerationConfig\n","\n","def interactive_chat(chat: ChatSession, prompt: str, search:bool) -> str:\n","\n","    tool = None\n","    if search:\n","      tool = Tool.from_google_search_retrieval(grounding.GoogleSearchRetrieval())\n","\n","    generation_config = {\n","        \"max_output_tokens\": 8192,\n","        \"temperature\": 1,\n","        \"top_p\": 0.95,\n","        \"top_k\": 40\n","    }\n","\n","    tools = [tool] if search else None\n","\n","    safety_settings = {\n","        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n","        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n","        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n","        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n","    }\n","\n","    responses = chat.send_message(\n","        prompt,\n","        generation_config = generation_config,\n","        safety_settings=safety_settings,\n","        tools = tools,\n","        stream=False\n","    )\n","    return responses.text\n","\n","#------------------------------------------------------------------------------------\n","\n","def get_chat_history(chat):\n","\n","  history = \" \".join([content.text for content in chat.history])\n","  return history\n","\n","#------------------------------------------------------------------------------------\n","def query_classification(chat_history, query):\n","\n","  prompt = f\"\"\"당신은 이전 대화 내용을  참조하여 <입력질문>을 분류해주는 AI Assistant 입니다.\n","  1. 질문 분류를 기준은 아래 <분류기준>을 참고하여 아래 내용을 포함된 정보로 분류해주세요.\n","     - 분류이유\n","     - 분류결과\n","     - Endpoint\n","\n","  2. 질문내의 키워드를 추출해서 정리해주세요.\n","\n","  <대화내용>{chat_history}</대화내용>\n","  <입력질문>{query}</입력질문>\n","\n","  <질문분류기준> [분류기준:endpoint]\n","  1. 영화추천 : http://media.com/영화추천\n","  2. 음악추천 : http://media.com/음악추천\n","  3. 기타 : http://media.com/기타\n","\n","  \"\"\"\n","\n","  response_schema = {\n","      \"type\": \"OBJECT\",\n","      \"properties\": {\n","        \"reason\": {\"type\": \"STRING\"},\n","        \"classification\": {\n","            \"type\": \"OBJECT\",\n","            \"properties\": {\n","              \"class\": {\"type\": \"STRING\"},\n","              \"endpoint\": {\"type\": \"STRING\"},\n","            },\n","        }\n","      }\n","  }\n","\n","  generation_config = GenerationConfig(\n","        temperature=0,\n","        top_p=1.0,\n","        top_k=10,\n","        candidate_count=1,\n","        max_output_tokens=8192,\n","        response_mime_type=\"application/json\",\n","        response_schema=response_schema\n","\n","    )\n","\n","  responses = model.generate_content(\n","      [prompt],\n","      generation_config=generation_config,\n","      stream=False,\n","  )\n","\n","  return responses.text\n","\n","#------------------------------------------------------------------------------------\n","\n","def agent_1(chat_history, query):\n","\n","  prompt =f\"\"\"\n","          당신은 영화정보를 제공하는AI 어시스턴트 입니다. 답변은 아래 내용을 따라서 답해주세요.\n","\n","          1. 영화 2~3개와 이유를 2줄 이내로 먼저 답변 해주세요.\n","          2. 영화를 선정 하는 이유를 설명 해주세요.\n","          3. 전체적인 답변은 간략하게 최대 10줄을 넘지 않게 해주세요.\n","\n","          <질문> : {query}\n","  \"\"\"\n","  tool = Tool.from_google_search_retrieval(grounding.GoogleSearchRetrieval())\n","\n","  responses = model.generate_content(\n","      [prompt],\n","      tools=[tool],\n","\n","  )\n","\n","  return responses.text\n","\n","def agent_2(chat_history, query):\n","\n","  prompt =f\"\"\"\n","          당신은 음악정보를 제공하는 AI 어시스턴트 입니다. 답변은 아래 내용을 따라서 답해주세요.\n","\n","          1. 오늘 날씨에 맞는 음악을 추천해주세요.\n","          2. 추천하는 이유를 자세히 설명해주세요.\n","          3. 전체적인 답변은 간략하게 최대 10줄을 넘지 않게 해주세요.\n","\n","          <질문> : {query}\n","\n","  \"\"\"\n","\n","  tool = Tool.from_google_search_retrieval(grounding.GoogleSearchRetrieval())\n","\n","  responses = model.generate_content(\n","      [prompt],\n","      tools=[tool],\n","  )\n","\n","  return responses.text\n","\n","def agent_3(chat_history, query):\n","\n","  prompt =f\"\"\"\n","          당신은 일상적인 대화가 가능한 AI Agent 입니다.\n","          가벼운 대화를 진행하되 혹시 질문이 있을 경우 해당 질문에 대해서 답변해주세요.\n","          전체 답변은 10줄을 넘지 않게 해주세요.\n","          <질문> : {query}\n","\n","  \"\"\"\n","\n","  tool = Tool.from_google_search_retrieval(grounding.GoogleSearchRetrieval())\n","\n","  responses = model.generate_content(\n","      [prompt],\n","      tools=[tool],\n","  )\n","\n","  return responses.text\n","\n","def agent_orchestration(chat_history, query):\n","\n","  classified = query_classification(chat_history, query)\n","  task = eval(classified)['classification']['class']\n","\n","  print(f\"Agent Task : {task}\")\n","\n","  if task == '영화추천':\n","    return agent_1(chat_history, query)\n","  elif task == '음악추천':\n","    return agent_2(chat_history, query)\n","  else:\n","    return agent_3(chat_history, query)\n"],"metadata":{"id":"6z9Xu9YIvbP7","executionInfo":{"status":"ok","timestamp":1735321003532,"user_tz":-540,"elapsed":23,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# @title AI Agent\n","\n","chat = model.start_chat()\n","\n","while True:\n","  query = input('사용자: ')\n","\n","  if query == '종료': break\n","\n","  chat_history = get_chat_history(chat)\n","\n","  response = agent_orchestration(chat_history, query)\n","  display(Markdown(f\"AI Agent : {response}\"))\n","  print(f\"------------------------------------ \")"],"metadata":{"id":"J4fRumi8v3Zm","colab":{"base_uri":"https://localhost:8080/","height":716},"outputId":"98c66ac7-6d5a-4244-86a4-8da3ae716a88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["사용자: 오늘 날씨 검색해서 그에 맞는 음악 추천해주세요.\n","Agent Task : 음악추천\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"AI Agent : 오늘(12월 27일) 날씨에 맞는 음악 추천입니다.  제공된 정보에 따르면, 서울의 날씨는 오전에 맑음에서 오후에 구름많음으로 변화하고, 강수확률은 오후에 30%입니다.  기온은 최저 -2도에서 최고 1도로 예상됩니다.  로스앤젤레스의 날씨는 대체로 맑음이며, 기온은 최저 50°F에서 최고 65°F입니다.\n\n따라서, 오늘 날씨에 맞는 음악 추천은 다음과 같습니다.\n\n1. **서울:** 오후에 쌀쌀하고 구름이 낄 가능성이 있으므로, 차분하고 따뜻한 느낌의 재즈나 팝 발라드를 추천합니다.  예를 들어, 노라 존스, 혹은 어쿠스틱 기타 연주곡이 좋습니다.  강수확률을 고려하여, 잔잔한 비오는 날의 감성을 담은 음악도 좋습니다.\n\n2. **로스앤젤레스:** 맑고 따뜻한 날씨이므로, 경쾌하고 밝은 분위기의 팝 음악이나 라틴 음악이 적합합니다.  활기찬 리듬과 긍정적인 가사의 음악을 통해 기분 좋은 하루를 보내실 수 있습니다.\n\n\n추운 날씨에는 따뜻한 느낌의 음악을, 맑은 날씨에는 밝고 경쾌한 음악을 듣는 것이 기분 전환에 도움이 됩니다.  날씨에 따라 음악을 선택하는 것은 개인의 취향에 따라 다를 수 있지만, 일반적으로 날씨와 음악의 분위기가 조화를 이루는 것이 좋습니다.  오늘 하루 즐거운 음악 감상으로 행복한 시간 보내시길 바랍니다.\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------------------------------ \n","사용자: 혹시 영화추천도 가능하나요 ?\n","Agent Task : 영화추천\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"AI Agent : 네, 영화 추천 가능합니다!\n\n1.  **추천 영화:**  2024년 개봉작 중 호평을 받은 `<악마와의 토크쇼>`와 `<퓨리오사: 매드맥스 사가>`를 추천합니다.  `<악마와의 토크쇼>`는 독특한 설정과 블랙코미디적 요소가 돋보이는 공포 영화이고, `<퓨리오사: 매드맥스 사가>`는 압도적인 액션과 스케일로 많은 기대를 받았던 작품입니다.\n\n\n2.  **선정 이유:**  두 영화 모두 2024년 개봉작 중에서  평단과 관객 모두에게 좋은 평가를 받았으며, 장르적으로도 차별화되어 다양한 취향을 만족시킬 수 있기 때문입니다.  하나는 독특한 공포 영화, 다른 하나는 액션 블록버스터로 서로 다른 매력을 가지고 있습니다.\n\n\n3.  최근 개봉작들을 중심으로 다양한 장르와 취향을 고려하여 추천해 드렸습니다.  더 자세한 정보는 왓챠피디아나 IMDb와 같은 영화 정보 사이트를 참고하시면 좋습니다.  선호하는 장르나 배우, 감독 등을 알려주시면 더욱 정확한 추천이 가능합니다.\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------------------------------ \n","사용자: 오늘 날씨를 검색해서 오늘 영화도 추천해주세요.\n","Agent Task : 영화추천\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"AI Agent : 오늘(12월 27일) 날씨는 강추위와 함께 중부지방은 눈이 날리는 곳도 있다고 합니다.  따라서 오늘 볼 영화로는 따뜻한 감성을 느낄 수 있는 영화와, 흥미진진한 스토리로 집중할 수 있는 영화를 추천합니다.\n\n1. **영화:**  \"윤희에게\" (잔잔한 감동과 아름다운 눈 풍경),  \"겨울왕국\" (화려한 애니메이션과 따뜻한 이야기)\n\n2. **선정 이유:** \"윤희에게\"는 눈 내리는 풍경과 어울리는 감성적인 분위기로 추운 날씨에 어울리고, \"겨울왕국\"은 화려한 애니메이션으로 추위를 잊게 해줄 즐거움을 제공하기 때문입니다.\n\n\n추운 날씨에 따뜻한 영화 감상으로 즐거운 시간 보내시길 바랍니다.\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------------------------------ \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"271CT9eLv4zq"},"execution_count":null,"outputs":[]}]}