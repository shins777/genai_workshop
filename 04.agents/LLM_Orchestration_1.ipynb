{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1NvlQ_LlpEMiaIPwHVdqzLRkn7dPgF7mw","timestamp":1730938797200},{"file_id":"1OPukqZbKSTcEA8lVK0D1An0F-mTpL4gm","timestamp":1730407430126}],"toc_visible":true,"authorship_tag":"ABX9TyNDBZj15g9ClshvL3x4C5Bb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","# Copyright 2024 Forusone(shins777@gmail.com)\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"metadata":{"id":"4rr1pppYJpcq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AI Agent - Orchestration with LLM"],"metadata":{"id":"fuw-Zef9zPwo"}},{"cell_type":"markdown","source":["## Set configuration"],"metadata":{"id":"xPIk2CC5J5wc"}},{"cell_type":"code","source":["# @title Package install\n","%pip install --upgrade --quiet --user google-cloud-aiplatform"],"metadata":{"id":"51-wpUMCJ-n1","executionInfo":{"status":"ok","timestamp":1735320480106,"user_tz":-540,"elapsed":3522,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# @title Authentication to access to GCP\n","\n","# To use markdown for output data from LLM\n","from IPython.display import display, Markdown\n","\n","# Use OAuth to access the GCP environment.\n","import sys\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"],"metadata":{"id":"MCBdMvcAJ78i","executionInfo":{"status":"ok","timestamp":1735320496851,"user_tz":-540,"elapsed":11115,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Lab Execution"],"metadata":{"id":"gCZP9ElhKXxG"}},{"cell_type":"code","source":["# @title Define constants\n","\n","PROJECT_ID = \"ai-hangsik\"  # @param {type:\"string\"}\n","LOCATION = \"us-central1\"  # @param {type:\"string\"}\n","MODEL_NAME = \"gemini-1.5-flash-002\" # @param {type:\"string\"}"],"metadata":{"cellView":"form","id":"ydJ5ZNXTKcjv","executionInfo":{"status":"ok","timestamp":1735320612055,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# @title Import packages\n","\n","import vertexai\n","\n","from vertexai.generative_models import (\n","    GenerationConfig,\n","    GenerativeModel,\n","    HarmBlockThreshold,\n","    HarmCategory,\n","    GenerationResponse,\n","    Tool,\n","    Part,\n","    ChatSession\n",")\n","\n","from vertexai.preview.generative_models import grounding"],"metadata":{"id":"7HFAX3FCKAEH","executionInfo":{"status":"ok","timestamp":1735320599624,"user_tz":-540,"elapsed":8407,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# @title Initialize Vertex AI\n","\n","# https://cloud.google.com/python/docs/reference/aiplatform/latest#initialization\n","vertexai.init(project=PROJECT_ID, location=LOCATION)\n","\n","# https://cloud.google.com/vertex-ai/generative-ai/docs/reference/python/latest/vertexai.generative_models.GenerativeModel\n","model = GenerativeModel(MODEL_NAME)"],"metadata":{"id":"9aqvBq1dKoXc","executionInfo":{"status":"ok","timestamp":1735320615664,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# @title Helper function\n","from vertexai.generative_models import ChatSession, GenerationConfig\n","\n","def interactive_chat(chat: ChatSession, prompt: str, search:bool) -> str:\n","\n","    tool = None\n","    if search:\n","      tool = Tool.from_google_search_retrieval(grounding.GoogleSearchRetrieval())\n","\n","    generation_config = {\n","        \"max_output_tokens\": 8192,\n","        \"temperature\": 1,\n","        \"top_p\": 0.95,\n","        \"top_k\": 40\n","    }\n","\n","    tools = [tool] if search else None\n","\n","    safety_settings = {\n","        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n","        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n","        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n","        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n","    }\n","\n","    responses = chat.send_message(\n","        prompt,\n","        generation_config = generation_config,\n","        safety_settings=safety_settings,\n","        tools = tools,\n","        stream=False\n","    )\n","    return responses.text\n","\n","#------------------------------------------------------------------------------------\n","\n","def get_chat_history(chat):\n","\n","  history = \" \".join([content.text for content in chat.history])\n","  return history\n","\n","#------------------------------------------------------------------------------------\n","def query_classification(chat_history, query):\n","\n","  prompt = f\"\"\"당신은 이전 대화 내용을 참조하여 <입력질문>을 분류해주는 AI Assistant 입니다.\n","  1. 질문 분류를 기준은 아래 <분류기준>을 참고하여 아래 내용을 포함된 정보로 분류해주세요.\n","     - 분류이유\n","     - 분류결과\n","     - Endpoint\n","\n","  2. 질문내의 키워드를 추출해서 정리해주세요.\n","\n","  <대화내용>{chat_history}</대화내용>\n","  <입력질문>{query}</입력질문>\n","\n","  <질문분류기준> [분류기준:endpoint]\n","  1. 제품 추천 : http://sec_vd.com/제품검색\n","  2. 대리점 추천 : http://sec_vd.com/대리점추천\n","  3. 번역테스트 : http://sec_vd.com/번역테스트\n","  4. 대리점 수리접수 : http://sec_vd.com/대리점수리접수\n","  5. 기타 : http://sec_vd.com/기타\n","\n","  \"\"\"\n","\n","  response_schema = {\n","      \"type\": \"OBJECT\",\n","      \"properties\": {\n","        \"reason\": {\"type\": \"STRING\"},\n","        \"classification\": {\n","            \"type\": \"OBJECT\",\n","            \"properties\": {\n","              \"class\": {\"type\": \"STRING\"},\n","              \"endpoint\": {\"type\": \"STRING\"},\n","            },\n","        }\n","      }\n","  }\n","\n","  generation_config = GenerationConfig(\n","        temperature=0,\n","        top_p=1.0,\n","        top_k=10,\n","        candidate_count=1,\n","        max_output_tokens=8192,\n","        response_mime_type=\"application/json\",\n","        response_schema=response_schema\n","\n","    )\n","\n","  responses = model.generate_content(\n","      [prompt],\n","      generation_config=generation_config,\n","      stream=False,\n","  )\n","\n","  return responses.text\n","\n","#------------------------------------------------------------------------------------\n","\n","def get_prompts(chat_history, query):\n","\n","  prompt_1 =f\"\"\"\n","          당신은 삼성 제품 추천을 위한 AI 어시스턴트 입니다. 답변은 아래 내용을 따라서 답해주세요.\n","\n","          1. 삼성 제품 추천에 대해서 제품명 2~3개와 이유를 2줄 이내로 먼저 답변 해주세요.\n","          2. 추천을 하는 지역위치는 최신 대화의 지역을 우선으로 추천해주세요.\n","          3. 질문 또는 대화내용에서 특정 위치를 알려주지 않으면 기본값으로 서울 지역을 기반으로 답해주세요.\n","          4. 사전 훈련된 지식에서 질문하는 지역에서 자주 언급되는 제품을 이용해서 추천해주시고, 이유를 알려주세요.\n","          5. 자세한 답변을 위해서 추가적으로 사용자의 관심사항(색상,크기,기능등을) 요청해주세요.\n","          6. 전체적인 답변은 간략하게 최대 10줄을 넘지 않게 해주세요.\n","\n","          <질문> : {query}\n","\n","  \"\"\"\n","\n","  prompt_2 = f\"\"\"당신은 삼성 가전 제품 사용자를 위해 번역해주는 AI 어시스턴트 입니다. 아래 내용에 맞게 번역해주세요.\n","\n","          1. 번역 대상 언어 선택은 가장 최근 대화를 참고해서 선택하고, 없다면 번역대상 언어 지정을 사용자에게 요청해주세요.\n","          2. 번역을 해야할 부분은 요청하는 문맥에 맞게 선택해서 번역해주세요.\n","          3. 특별하게 번역해야 할 부분을 제시하지 않으면 전체 문장을 번역해주세요.\n","          4. 답변은 최대한 간략하게 번역된 부분만 표현하고 설명하지 말아주세요.\n","\n","          <번역을 위한 질문> : {query}\n","\n","  \"\"\"\n","\n","  prompt_3 = f\"\"\"당신은 삼성 제품 사용자를 위해 삼성 대리점 위치 추천해주는 AI Assistant입니다.\n","\n","          1. 질문에 맞는 삼성제품을 구매할 수 있는 대리점 명을 3~4개 정도 추천해주세요.\n","          2. 해당 대리점의 주소를 알려주고 왜 추천하는지 알려주세요.\n","          3. 전체적인 답변은 최대 10줄을 넘지 않게 해주세요.\n","\n","          <질문> : {query}\n","\n","  \"\"\"\n","\n","  prompt_4 = f\"\"\"당신은 삼성제품 사용자를 위해 대리점 수리 접수를 도와주는 AI Assistant입니다.\n","\n","          1. 수리접수를 위한 수리점 위치는 최신 대화의 지역을 우선으로 구글에서 검색해서 추천해주세요.\n","          2. 질문 또는 대화내용에서 특정 위치를 알려주지 않으면 기본값으로 서울 지역을 기반으로 답해주세요.\n","          3. 수리점의 정확한 주소와 전화번호를 같이 보여주세요.\n","          4. 만일 정확한 지역정보 또는 수리점 위치를 모를 때는 해당 위치정보를 요청해주세요.\n","          5. 전체적인 답변은 간략하게 최대 10줄을 넘지 않게 해주세요.\n","\n","          <질문> : {query}\n","\n","  \"\"\"\n","\n","  prompt_5 = f\"\"\"당신은 삼성제품 사용자의 질문에 답변을 해주는 AI Assistant입니다.\n","          사용자의 다양한 질문에 대해서 검색 결과를 활용해서 답변 해주세요.\n","          가급적 답변은 10줄 이내로 짧고 간략하게 답해주세요.\n","          <질문> : {query}\n","\n","  \"\"\"\n","\n","  classified = query_classification(chat_history, query)\n","\n","  task = eval(classified)['classification']['class']\n","  print(f\"Selected Task : {task}\")\n","  if task == '제품 추천':\n","    return prompt_1, True\n","  elif task == '번역테스트':\n","    return prompt_2, False\n","  elif task == '대리점 추천':\n","    return prompt_3, True\n","  elif task == '대리점 수리접수':\n","    return prompt_4, True\n","  elif task == '기타':\n","    return prompt_5, True\n","  else:\n","    return prompt_5, True\n"],"metadata":{"id":"6z9Xu9YIvbP7","executionInfo":{"status":"ok","timestamp":1735320707644,"user_tz":-540,"elapsed":49,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# @title AI Agent\n","\n","chat = model.start_chat()\n","\n","search = True\n","\n","while True:\n","  query = input('사용자: ')\n","\n","  if query == '종료': break\n","\n","  chat_history = get_chat_history(chat)\n","\n","  prompt, search = get_prompts(chat_history, query)\n","\n","  response = interactive_chat(chat, prompt, search)\n","  display(Markdown(f\"AI Agent : {response}\"))\n","  print(f\"------------------------------------ \")"],"metadata":{"id":"J4fRumi8v3Zm","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"ok","timestamp":1735320749543,"user_tz":-540,"elapsed":38077,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"5ef21037-ef65-4169-a9be-c569c0b17e73"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["사용자: 안녕하세요.\n","Selected Task : 기타\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"AI Agent : 안녕하세요! 삼성 제품 사용에 대한 질문이 있으시면 언제든지 편하게 물어보세요.  최선을 다해 도와드리겠습니다.\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------------------------------ \n","사용자: 삼성 냉장고는 어디서 사야 하나요 ?\n","Selected Task : 대리점 추천\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"AI Agent : 삼성 냉장고는 삼성 디지털프라자, 백화점, 또는 온라인 삼성닷컴에서 구매하실 수 있습니다.  정확한 대리점 위치는 거주 지역에 따라 다르므로, 삼성전자 홈페이지의 매장 찾기 기능을 이용하시면 가까운 곳을 찾으실 수 있습니다.  \n\n추천 대리점은 다음과 같습니다. (단,  구체적인 주소와 추천 이유는 제공된 정보만으로는 확인이 불가능합니다.  가까운 매장을 삼성전자 홈페이지에서 확인해주세요.)\n\n1. 삼성 디지털프라자 (가장 가까운 지점) : 다양한 삼성 제품과 전문 상담을 받을 수 있습니다.\n2. 롯데백화점 (가전 매장이 있는 지점) :  다른 브랜드 제품과 비교하며 쇼핑 가능합니다.\n3.  온라인 삼성닷컴: 편리하게 온라인으로 구매 가능하며 다양한 할인 혜택을 확인할 수 있습니다.\n\n보다 정확한 정보를 위해서는  삼성전자 홈페이지의 매장찾기 서비스를 이용하는 것이 좋습니다.\n"},"metadata":{}},{"name":"stdout","output_type":"stream","text":["------------------------------------ \n","사용자: 종료\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"271CT9eLv4zq"},"execution_count":null,"outputs":[]}]}