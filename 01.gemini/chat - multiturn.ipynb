{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQJknXG7C9Dq"
   },
   "source": [
    "# Disclaimer & Copyright\n",
    "\n",
    "Copyright 2024 Forusone : shins777@gmail.com\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB93wBDYDCPI"
   },
   "source": [
    "# Gemini - Chat operation\n",
    "* This notebook shows you how to send chat prompts to the Gemini\n",
    "You can interact with Gemini using a single-turn prompt and response or chat with it in a multi-turn, continuous conversation, even for code understanding and generation.\n",
    "* Refer to https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/send-chat-prompts-gemini\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vuxu3iRDDtcl"
   },
   "source": [
    "# Configuration\n",
    "## Install python packages\n",
    "* Vertex AI SDK for Python\n",
    "  * https://cloud.google.com/python/docs/reference/aiplatform/latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21491,
     "status": "ok",
     "timestamp": 1731645154046,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "wevZD-jnD-ft",
    "outputId": "c1afbba6-ee34-4d90-9104-ab552f260465",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731645154047,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "-nhL4T2sKsdp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCVttGUsEzgj"
   },
   "source": [
    "## Authentication to access to the GCP & Google drive\n",
    "\n",
    "* Use OAuth to access the GCP environment.\n",
    " * Refer to the authentication methods in GCP : https://cloud.google.com/docs/authentication?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13593,
     "status": "ok",
     "timestamp": 1731645167638,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "AJuo1g4bE3-x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  For only colab to authenticate to get an access to the GCP.\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ey_Bv55hIblt"
   },
   "source": [
    "## Set the environment on GCP Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1731645167638,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "XJwhurOUHIG-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME=\"gemini-1.5-flash\"\n",
    "PROJECT_ID=\"ai-hangsik\"\n",
    "REGION=\"asia-northeast3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xk3nZQQhIiom"
   },
   "source": [
    "### Vertex AI initialization\n",
    "Configure Vertex AI and access to the foundation model.\n",
    "* Vertex AI initialization : aiplatform.init(..)\n",
    "  * https://cloud.google.com/python/docs/reference/aiplatform/latest#initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 7235,
     "status": "ok",
     "timestamp": 1731645174872,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "HZ6WeWz4HIEW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import vertexai.generative_models as generative_models\n",
    "\n",
    "# Initalizate the current vertex AI execution environment.\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "\n",
    "system_instructions = [\n",
    " \"You are an AI Specialist\",\n",
    " \"Answer to the question in detail\"\n",
    "]\n",
    "\n",
    "# Access to the generative model.\n",
    "model = GenerativeModel(MODEL_NAME,\n",
    "                        system_instruction=system_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4NbkJ4HJYBB"
   },
   "source": [
    "### Function to get the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1731645176424,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "sMaCwPVGJXX6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.generative_models import ChatSession\n",
    "\n",
    "def interactive_chat(chat: ChatSession, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a response from the model.\n",
    "\n",
    "    - chat : ChatSession Chat session object\n",
    "    - prompt : str - The prompt to send to the model.\n",
    "    - returns: str - The generated response.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set model parameter : https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/send-multimodal-prompts#set_model_parameters\n",
    "    generation_config = {\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.95,\n",
    "    }\n",
    "\n",
    "    # Configure satey setting : https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes\n",
    "    # Refer to the link to remove : https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes#how_to_remove_automated_response_blocking_for_select_safety_attributes\n",
    "    safety_settings = {\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    }\n",
    "\n",
    "    text_response = []\n",
    "\n",
    "    # https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.ChatSession\n",
    "    responses = chat.send_message(\n",
    "        question,\n",
    "        generation_config = generation_config,\n",
    "        safety_settings = safety_settings,\n",
    "        tools = None,\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return responses.text\n",
    "\n",
    "def get_chat_history(chat):\n",
    "\n",
    "  history = \" \".join([content.text for content in chat.history])\n",
    "  print(f\"---------------- Chat history ---------------- \")\n",
    "  print(history)\n",
    "\n",
    "# ì´ê²ƒì´ ë³€ê²½ì´ ë˜ì–´ì•¼ í•¨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGdT-2WHJuXf"
   },
   "source": [
    "## AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "executionInfo": {
     "elapsed": 124285,
     "status": "ok",
     "timestamp": 1731645344160,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "ln_Jadw9w0Ew",
    "outputId": "73257cb9-3cb4-4977-abab-4fb4179910b6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì:  ì•ˆë…•í•˜ì„¸ìš”.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "AI Agent : ì•ˆë…•í•˜ì„¸ìš”! ì‚¼ì„±ì „ì ê°€ì „ì œí’ˆ êµ¬ë§¤ë¥¼ ë„ì™€ë“œë¦´ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? í˜¹ì‹œ ê¶ê¸ˆí•œ ì œí’ˆì´ë‚˜ ì°¾ìœ¼ì‹œëŠ” ê¸°ëŠ¥ì´ ìˆìœ¼ì‹ ê°€ìš”?  ë‹¤ì–‘í•œ ì‚¼ì„± ê°€ì „ì œí’ˆ ì •ë³´ì™€ ìµœì‹  ê¸°ëŠ¥, í• ì¸ ì •ë³´ê¹Œì§€ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆë‹µë‹ˆë‹¤! ğŸ˜Š \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì:  í˜¹ì‹œ ê³¼ì²œì—ì„œ ì–´ë–»ê²Œ ëƒ‰ì¥ê³ ë¥¼ ì‚¬ì•¼ í•˜ë‚˜ìš” ?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "AI Agent : ê³¼ì²œì—ì„œ ì‚¼ì„± ëƒ‰ì¥ê³ ë¥¼ êµ¬ë§¤í•˜ì‹œë ¤ëŠ”êµ°ìš”!  ê°€ì¥ í¸ë¦¬í•œ ë°©ë²•ì€ ì‚¼ì„± ë””ì§€í„¸í”„ë¼ì ê³¼ì²œì ì„ ë°©ë¬¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ëƒ‰ì¥ê³  ëª¨ë¸ì„ ì§ì ‘ ë³´ê³  ë¹„êµí•˜ë©° ì „ë¬¸ ìƒë‹´ê¹Œì§€ ë°›ì„ ìˆ˜ ìˆì–´ìš”.  í˜¹ì‹œ ì˜¨ë¼ì¸ êµ¬ë§¤ë¥¼ ì„ í˜¸í•˜ì‹ ë‹¤ë©´, ì‚¼ì„±ë‹·ì»´ì´ë‚˜ ì¿ íŒ¡, Gë§ˆì¼“ ë“± ì˜¨ë¼ì¸ ì‡¼í•‘ëª°ì—ì„œ í¸ë¦¬í•˜ê²Œ êµ¬ë§¤ ê°€ëŠ¥í•©ë‹ˆë‹¤.  ë°°ì†¡ì€ ì§ì ‘ ë°›ìœ¼ì‹œê±°ë‚˜, ì„¤ì¹˜ ì„œë¹„ìŠ¤ë¥¼ ì‹ ì²­í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ êµ¬ë§¤í•˜ì‹œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?  ğŸ˜Š \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì:  í˜¹ì‹œ ì£¼ì†Œê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš” ?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "AI Agent : ê³¼ì²œ ì‚¼ì„± ë””ì§€í„¸í”„ë¼ì ë°©ë¬¸ì„ ì›í•˜ì‹œëŠ”êµ°ìš”!  ì£¼ì†ŒëŠ” ê²½ê¸°ë„ ê³¼ì²œì‹œ ë³„ì–‘ë™ 1-10ë²ˆì§€, ê³¼ì²œ ë¡¯ë°ë°±í™”ì  7ì¸µì…ë‹ˆë‹¤.  ë¡¯ë°ë°±í™”ì  7ì¸µì— ìœ„ì¹˜í•˜ê³  ìˆì–´ ì‡¼í•‘ê³¼ í•¨ê»˜ í¸ë¦¬í•˜ê²Œ ë°©ë¬¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  í˜¹ì‹œ ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?  ğŸ˜Š \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì:  ë¡¯ë°ë°±í™”ì ì€ ì—†ëŠ”ê²ƒìœ¼ë¡œ ì•Œê³  ìˆì–´ìš”.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "AI Agent : ì•—, ì£„ì†¡í•©ë‹ˆë‹¤!  ì œê°€ ì˜ëª»ëœ ì •ë³´ë¥¼ ë“œë ¸ë„¤ìš”.  ê³¼ì²œì—ëŠ” ë¡¯ë°ë°±í™”ì ì´ ì—†ê³ , ì‚¼ì„± ë””ì§€í„¸í”„ë¼ìëŠ” ê³¼ì²œì‹œ ë³„ì–‘ë™ 1-10ë²ˆì§€,  **ê³¼ì²œ ë†í˜‘ í•˜ë‚˜ë¡œë§ˆíŠ¸ 1ì¸µ**ì— ìœ„ì¹˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.  í˜¹ì‹œ ë†í˜‘ í•˜ë‚˜ë¡œë§ˆíŠ¸ ê·¼ì²˜ì— ë°©ë¬¸ ê³„íšì´ ìˆìœ¼ì‹ ê°€ìš”?  ì‚¼ì„± ë””ì§€í„¸í”„ë¼ìì—ì„œ ë‹¤ì–‘í•œ ëƒ‰ì¥ê³  ëª¨ë¸ì„ ì§ì ‘ ë³´ì‹œê³ , ì „ë¬¸ ìƒë‹´ë„ ë°›ì•„ë³´ì„¸ìš”.  ğŸ˜Š \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì:  ë†í˜‘ í•˜ë‚˜ë¡œ ë§ˆíŠ¸ ê·¼ì²˜ì— ì–´ë–¤ ì•„íŒŒíŠ¸ê°€ ìˆë‚˜ìš” ?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "AI Agent : ê³¼ì²œ ë†í˜‘ í•˜ë‚˜ë¡œë§ˆíŠ¸ ê·¼ì²˜ì—ëŠ” ë‹¤ì–‘í•œ ì•„íŒŒíŠ¸ ë‹¨ì§€ë“¤ì´ ìˆë‹µë‹ˆë‹¤!  ì£¼ë³€ì— ìœ„ì¹˜í•œ ì•„íŒŒíŠ¸ ë‹¨ì§€ë¡œëŠ”  **ê³¼ì²œ ì£¼ê³µ 1ë‹¨ì§€**, **ê³¼ì²œ ì£¼ê³µ 2ë‹¨ì§€**, **ê³¼ì²œ ì£¼ê³µ 3ë‹¨ì§€**, **ê³¼ì²œ ì£¼ê³µ 4ë‹¨ì§€**, **ê³¼ì²œ ì£¼ê³µ 6ë‹¨ì§€**, **ê³¼ì²œ ì£¼ê³µ 7ë‹¨ì§€**, **ë˜ë¯¸ì•ˆ ê³¼ì²œ ì„¼íŠ¸ëŸ´ ìŠ¤ìœ„íŠ¸**, **ê³¼ì²œ ìœ„ë¸Œ**, **ê³¼ì²œ í‘¸ë¥´ì§€ì˜¤ ì¨ë°‹** ë“±ì´ ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì•„íŒŒíŠ¸ì— ê±°ì£¼í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì‹œë©´ ëƒ‰ì¥ê³  ì„ íƒì— ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!  ğŸ˜Š \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì:  TV ë„ ì‚´ìˆ˜ ìˆë‚˜ìš” ?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "AI Agent : ë„¤, ë¬¼ë¡ ì´ì£ ! ì‚¼ì„± ë””ì§€í„¸í”„ë¼ì ê³¼ì²œì ì—ì„œëŠ” ëƒ‰ì¥ê³ ë¿ë§Œ ì•„ë‹ˆë¼ TVë„ êµ¬ë§¤ ê°€ëŠ¥í•©ë‹ˆë‹¤. ìµœì‹  QLED TVë¶€í„° 8K TVê¹Œì§€ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì§ì ‘ ë³´ê³  ë¹„êµí•˜ë©° êµ¬ë§¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  TV êµ¬ë§¤ë¥¼ ì›í•˜ì‹ ë‹¤ë©´,  ì‚¼ì„± ë””ì§€í„¸í”„ë¼ì ê³¼ì²œì ì— ë°©ë¬¸í•˜ì…”ì„œ  ì§ì›ì—ê²Œ ë¬¸ì˜í•˜ì‹œë©´ ì¹œì ˆí•˜ê²Œ ìƒë‹´í•´ë“œë¦´ ê±°ì˜ˆìš”.  í˜¹ì‹œ ì›í•˜ëŠ” TV ëª¨ë¸ì´ë‚˜ ê¸°ëŠ¥ì´ ìˆìœ¼ì‹ ê°€ìš”?  ğŸ˜Š \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì:  ì¢…ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# @title AI Agent\n",
    "\n",
    "chat = model.start_chat()\n",
    "\n",
    "while True:\n",
    "  query = input('ì‚¬ìš©ì: ')\n",
    "\n",
    "  if query == 'ì¢…ë£Œ': break\n",
    "\n",
    "  # chat_history = get_chat_history(chat)\n",
    "\n",
    "  prompt = f\"\"\"\n",
    "  ë‹¹ì‹ ì€ ì‚¼ì„±ì „ì ê°€ì „ ì œí’ˆì˜ êµ¬ë§¤ë¥¼ ë„ì™€ ì£¼ëŠ” AI Assistant ì…ë‹ˆë‹¤.\n",
    "  ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ì¹œì ˆí•˜ê²Œ 10ì¤„ ì´ë‚´ë¡œ ë‹µí•´ì£¼ì„¸ìš”.\n",
    "  ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì‚¼ì„±ì „ì ì œí’ˆì„ ì‚´ìˆ˜ ìˆë„ë¡ ë„ì™€ ì¤˜ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "  ì§ˆë¬¸ : {query}\n",
    "  \"\"\"\n",
    "\n",
    "  response = interactive_chat(chat, prompt)\n",
    "  display(Markdown(f\"AI Agent : {response}\"))\n",
    "  print(f\"------------------------------------ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP7ai7JnEDn6H+X+Je3DFHi",
   "provenance": [
    {
     "file_id": "10QiVBSVRSu69Uhr9OpzX3-8CFvMdG4EZ",
     "timestamp": 1717906152865
    },
    {
     "file_id": "1btZCldJxz-DFxshEjVFBksH3cFZ7ZWzY",
     "timestamp": 1717886695950
    }
   ],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
