{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10QiVBSVRSu69Uhr9OpzX3-8CFvMdG4EZ","timestamp":1717906152865},{"file_id":"1btZCldJxz-DFxshEjVFBksH3cFZ7ZWzY","timestamp":1717886695950}],"toc_visible":true,"authorship_tag":"ABX9TyOkRK3tacm48gotmwnfNQBG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Disclaimer & Copyright\n","\n","Copyright 2024 Forusone : shins777@gmail.com\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."],"metadata":{"id":"OQJknXG7C9Dq"}},{"cell_type":"markdown","source":["# Gecko embedding - Korean text embedding test\n","* This notebook explains how to use Korean embeddings and understand vectorization.\n","* Refer to the link for more information about the embeddings.\n"," * https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings\n"],"metadata":{"id":"zB93wBDYDCPI"}},{"cell_type":"markdown","source":["# Configuration\n","## Install python packages\n","* Vertex AI SDK for Python\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest"],"metadata":{"id":"Vuxu3iRDDtcl"}},{"cell_type":"code","source":["%pip install --upgrade --quiet google-cloud-aiplatform"],"metadata":{"id":"wevZD-jnD-ft","executionInfo":{"status":"ok","timestamp":1718243567768,"user_tz":-540,"elapsed":9787,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display, Markdown"],"metadata":{"id":"-nhL4T2sKsdp","executionInfo":{"status":"ok","timestamp":1718243567768,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Authentication to access to the GCP & Google drive\n","\n","* Use OAuth to access the GCP environment.\n"," * Refer to the authentication methods in GCP : https://cloud.google.com/docs/authentication?hl=ko"],"metadata":{"id":"tCVttGUsEzgj"}},{"cell_type":"code","source":["#  For only colab to authenticate to get an access to the GCP.\n","import sys\n","\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"],"metadata":{"id":"AJuo1g4bE3-x","executionInfo":{"status":"ok","timestamp":1718243568374,"user_tz":-540,"elapsed":609,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["* Mount to the google drive to access the .ipynb files in the repository.\n","\n"],"metadata":{"id":"mQoisCsVE6LM"}},{"cell_type":"code","source":["# To access contents in Google drive\n","\n","if \"google.colab\" in sys.modules:\n","  from google.colab import drive\n","  drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhluEayrE_Io","executionInfo":{"status":"ok","timestamp":1718243571130,"user_tz":-540,"elapsed":2759,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"827d2c6b-75f0-490d-a9e2-ad17b6dbb425"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Set the environment on GCP Project\n","* Configure project information\n","  * Model name : LLM model name : https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n","  * Project Id : prodect id in GCP\n","  * Region : region name in GCP"],"metadata":{"id":"ey_Bv55hIblt"}},{"cell_type":"code","source":["MODEL_NAME=\"gemini-1.5-flash\"\n","PROJECT_ID=\"ai-hangsik\"\n","REGION=\"asia-northeast3\""],"metadata":{"id":"XJwhurOUHIG-","executionInfo":{"status":"ok","timestamp":1718243571131,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Vertex AI initialization\n","Configure Vertex AI and access to the foundation model.\n","* Vertex AI initialization : aiplatform.init(..)\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest#initialization"],"metadata":{"id":"Xk3nZQQhIiom"}},{"cell_type":"code","source":["import vertexai\n","from vertexai.preview.generative_models import GenerativeModel, Part\n","import vertexai.preview.generative_models as generative_models\n","\n","# Initalizate the current vertex AI execution environment.\n","vertexai.init(project=PROJECT_ID, location=REGION)\n","\n","# Access to the generative model.\n","# model = GenerativeModel(MODEL_NAME)"],"metadata":{"id":"HZ6WeWz4HIEW","executionInfo":{"status":"ok","timestamp":1718243577650,"user_tz":-540,"elapsed":6522,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Functions to evaluate similarity"],"metadata":{"id":"Vyy_2mTU-cAT"}},{"cell_type":"code","source":["import numpy as np\n","import torch.nn as nn\n","\n","\"\"\" torch matrix multiplication \"\"\"\n","def cal_mm(a, b):\n","  if len(a.shape) == 1: a = a.unsqueeze(0)\n","  if len(b.shape) == 1: b = b.unsqueeze(0)\n","\n","  a_norm = a / a.norm(dim=1)[:, None]\n","  b_norm = b / b.norm(dim=1)[:, None]\n","  return torch.mm(a_norm, b_norm.transpose(0, 1)) * 100\n","\n","\"\"\" torch cosine similarity \"\"\"\n","def cal_cosine(a, b):\n","  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","  output = cos(a, b)\n","  return output\n","\n","\"\"\" torch dot product similarity \"\"\"\n","def cal_dot_product(a, b):\n","  a1= a[0]\n","  b1= b[0]\n","  return torch.dot(a1, b1)"],"metadata":{"id":"0zfzE9tq9ye7","executionInfo":{"status":"ok","timestamp":1718243581683,"user_tz":-540,"elapsed":4034,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Gecko Embeddings modules\n","* https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings#generative-ai-get-text-embedding-python_vertex_ai_sdk"],"metadata":{"id":"3rdHZWBtRAvf"}},{"cell_type":"code","source":["from typing import List, Optional\n","from vertexai.preview.language_models import TextEmbeddingModel\n","\n","vertexai.init(project=PROJECT_ID, location=REGION)\n","gecko_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-multilingual@latest\")\n","\n","# Define an embedding method that uses the model\n","def gecko_embeddings(sentences: List[str],model: TextEmbeddingModel) -> List[Optional[List[float]]]:\n","    try:\n","        embeddings = model.get_embeddings(sentences)\n","        return [embedding.values for embedding in embeddings]\n","    except Exception as e:\n","        print(f\"Exception : {str(e)}\")\n","        return [None for _ in range(len(sentences))]"],"metadata":{"id":"Mp2YF-k8Qt_y","executionInfo":{"status":"ok","timestamp":1718243582999,"user_tz":-540,"elapsed":1319,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\n","sentence0 = \"\"\" 2024년에는 인공지능 기술을 활용한 다양한 고객서비스에 대한 요구를 많이 한다. \"\"\"\n","\n","sentence1 = \"\"\" 2024년에는 경기 둔화 여파로 사람들은 절약을 할 것이고 인공지능 기술을 활용한 다양한 고객서비스에 대한 요구를 많이 한다.\n","인공지능을 활용하기 위한 고객 서비스는 다양한 형태의 활용사례를 만들수 있으며, 금융회사의 고객 상담 센터가 가장 적합한 형태의 서비스가 될 가능성이 있다.\n","기타 다양한 산업 분야에서의 지식검색을 통한 고객서비스도 좋은 사례가 될수 있다.\n","\"\"\"\n","\n","sentence2 = \"\"\" 2024년 금융소비 트렌드와 금융 기회를 보면 2024년에는 경기 둔화의 여파로 안전하고 절약 지향적인 재무관리 태도가 소비자의 금융생활 전반에 확산될 전망이다.\n","또한, 인공지능(AI) 등 디지털 혁신이 고도화되면서 1:1 맞춤형 자산관리나 웨어러블(Wearable) 기반의 간편 결제 서비스에 대한 기대는 점점 커지고 있다.\n","사회적 의식이 성숙하면서 금융권의 책임경영이 중시되는 경향과 연령이 낮아지는 미래 손님군의 특징도 눈여겨 볼만하다.\n","\"\"\"\n","\n","sentence3 = \"\"\" 피아노는 17세기 말, 이탈리아의 피렌체에서 처음으로 그 모습을 드러냈다.\n","피아노는 제작자 ‘바르톨로메오 크리스토포리(Bartolomeo Cristofori, 1655-1732)’가 처음 발명한 것으로 추측되며,\n","당시 크리스토포리는 피렌체를 대표하는 가문 ‘메디치’를 위해 건반악기를 제작하고 있었다. 피아노의 전신 하프시코드, 스피넷등을 제작하던 크리스토포리는 1689년경 피아노 제작에 착수했을 것으로 추정되며,\n","1710년경에는 피아노 3대를 완성했다는 기록이 남아있다.\n","\"\"\"\n","\n","sentence4 = \"\"\" 2024년에는 사람들은 점점 소비를 줄이게 될것이다. \"\"\"\n","\n","# sentence0 =\"호랑이가 토끼를 쫒아간다\"\n","# sentence1 =\"토끼가 호랑이에게 쫒긴다\"\n","# sentence2 =\"호랑이가 토끼 뒤에 있다\"\n","# sentence3 =\"호랑이 같은 고양이가 토끼를 쫒고 있다\"\n","# sentence4 =\"고양이가 사슴을 보고 있다\"\n"],"metadata":{"id":"w6k-cwzU9ycb","executionInfo":{"status":"ok","timestamp":1718243582999,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","sentences = [sentence0, sentence1, sentence2, sentence3, sentence4]\n","sentence_embeddings = gecko_embeddings(sentences=sentences, model = gecko_model )\n","\n","tensor_embed = torch.Tensor(sentence_embeddings)\n","\n","mm_score0 = cal_mm(tensor_embed[0],tensor_embed[0] )\n","mm_score1 = cal_mm(tensor_embed[0],tensor_embed[1] )\n","mm_score2 = cal_mm(tensor_embed[0],tensor_embed[2] )\n","mm_score3 = cal_mm(tensor_embed[0],tensor_embed[3] )\n","mm_score4 = cal_mm(tensor_embed[0],tensor_embed[4] )\n","\n","print(f\"mm_score0[{mm_score0}]\")\n","print(f\"mm_score1[{mm_score1}]\")\n","print(f\"mm_score2[{mm_score2}]\")\n","print(f\"mm_score3[{mm_score3}]\")\n","print(f\"mm_score4[{mm_score4}]\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CYw8VmiSZBx","executionInfo":{"status":"ok","timestamp":1718243584698,"user_tz":-540,"elapsed":1701,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"d13f633b-9262-4a99-c301-cddad5bb44f0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["mm_score0[tensor([[100.0000]])]\n","mm_score1[tensor([[91.9990]])]\n","mm_score2[tensor([[82.9323]])]\n","mm_score3[tensor([[54.8020]])]\n","mm_score4[tensor([[80.3105]])]\n"]}]}]}